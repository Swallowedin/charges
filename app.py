import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import json
import re
import io
import base64
from openai import OpenAI
from PIL import Image
import PyPDF2
import docx2txt
import pytesseract
import cv2
import numpy as np
import os
import hashlib

# Configuration de la page
st.set_page_config(
    page_title="Analyseur de Documents avec GPT-4o-mini",
    page_icon="üìä",
    layout="wide"
)

# Initialisation de l'√©tat de la session
if 'analysis_complete' not in st.session_state:
    st.session_state.analysis_complete = False
if 'analysis_cache' not in st.session_state:
    st.session_state.analysis_cache = {}

# Configuration de l'API OpenAI
OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"] if "OPENAI_API_KEY" in st.secrets else os.getenv('OPENAI_API_KEY')
if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY n'est pas d√©fini dans les variables d'environnement")

client = OpenAI(api_key=OPENAI_API_KEY)

# Fonction pour extraire le texte d'une image avec OCR
def extract_text_from_image(uploaded_file):
    """Extraire le texte d'une image avec OCR"""
    try:
        # Convertir le fichier en image
        image_bytes = uploaded_file.getvalue()
        nparr = np.frombuffer(image_bytes, np.uint8)
        img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        # Pr√©traitement de l'image pour am√©liorer l'OCR
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # Appliquer l'OCR
        text = pytesseract.image_to_string(thresh, lang='fra')
        
        return text
    except Exception as e:
        st.error(f"Erreur lors de l'extraction du texte de l'image: {str(e)}")
        return ""

# Fonctions pour extraire le texte de diff√©rents types de fichiers
def extract_text_from_pdf(uploaded_file):
    """Extraire le texte d'un fichier PDF"""
    text = ""
    try:
        pdf_reader = PyPDF2.PdfReader(uploaded_file)
        for page_num in range(len(pdf_reader.pages)):
            text += pdf_reader.pages[page_num].extract_text() + "\n"
        return text
    except Exception as e:
        st.error(f"Erreur lors de l'extraction du texte du PDF: {str(e)}")
        return ""

def extract_text_from_docx(uploaded_file):
    """Extraire le texte d'un fichier Word"""
    try:
        text = docx2txt.process(uploaded_file)
        return text
    except Exception as e:
        st.error(f"Erreur lors de l'extraction du texte du fichier Word: {str(e)}")
        return ""

def extract_text_from_txt(uploaded_file):
    """Extraire le texte d'un fichier TXT"""
    try:
        return uploaded_file.getvalue().decode("utf-8")
    except Exception as e:
        st.error(f"Erreur lors de l'extraction du texte du fichier TXT: {str(e)}")
        return ""

def get_file_content(uploaded_file):
    """Obtenir le contenu du fichier selon son type"""
    if uploaded_file is None:
        return ""
        
    file_type = uploaded_file.type
    
    if file_type == "application/pdf":
        return extract_text_from_pdf(uploaded_file)
    elif file_type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
        return extract_text_from_docx(uploaded_file)
    elif file_type == "text/plain":
        return extract_text_from_txt(uploaded_file)
    elif file_type.startswith("image/"):
        return extract_text_from_image(uploaded_file)
    else:
        st.warning(f"Type de fichier non pris en charge: {file_type}")
        return ""

def process_multiple_files(uploaded_files):
    """Traiter plusieurs fichiers et concat√©ner leur contenu"""
    combined_text = ""
    
    for file in uploaded_files:
        # Obtenir le contenu du fichier
        file_content = get_file_content(file)
        if file_content:
            combined_text += f"\n\n--- D√©but du fichier: {file.name} ---\n\n"
            combined_text += file_content
            combined_text += f"\n\n--- Fin du fichier: {file.name} ---\n\n"
    
    return combined_text

def get_content_hash(text1, text2):
    """G√©n√®re un hash unique pour les entr√©es combin√©es"""
    combined = (text1 or "") + "|" + (text2 or "")
    return hashlib.md5(combined.encode('utf-8')).hexdigest()

def analyze_with_openai(text1, text2, document_type):
    """
    Analyse les documents avec OpenAI, avec mise en cache pour des r√©sultats coh√©rents
    """
    try:
        # G√©n√©rer un hash unique pour cette combinaison de documents
        content_hash = get_content_hash(text1, text2)
        
        # V√©rifier si l'analyse est d√©j√† en cache
        if content_hash in st.session_state.analysis_cache:
            st.success("R√©sultat r√©cup√©r√© du cache (analyse pr√©c√©dente identique)")
            return st.session_state.analysis_cache[content_hash]
        
        prompt = f"""
        # Analyse de documents
        
        ## Contexte
        Document type: {document_type}
        
        ## Document 1
        {text1[:10000]}
        
        ## Document 2
        {text2[:10000]}
        
        ## T√¢che
        1. Extraire les informations cl√©s des documents
        2. Identifier les th√®mes principaux
        3. Analyser la coh√©rence entre les documents
        4. Formuler des observations pertinentes
        
        ## Format JSON
        {{
            "document1_analysis":[{{"title":"","content":""}}],
            "document2_analysis":[{{"title":"","content":""}}],
            "themes": [""],
            "coherence_analysis": {{"coherence_level":"√©lev√©e|moyenne|faible","details":""}},
            "observations": [""]
        }}
        """

        # Essayer d'abord avec gpt-4o-mini
        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,  # R√©duire la temp√©rature pour plus de coh√©rence
                seed=42,  # Assurer la coh√©rence des r√©sultats
                response_format={"type": "json_object"}  # Forcer une r√©ponse JSON
            )
            result = json.loads(response.choices[0].message.content)
            st.success("Analyse r√©alis√©e avec gpt-4o-mini")
            
        except Exception as e:
            st.warning(f"Erreur avec gpt-4o-mini: {str(e)}. Tentative avec gpt-3.5-turbo...")
            
            # Si √©chec, basculer vers gpt-3.5-turbo
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,  # R√©duire la temp√©rature pour plus de coh√©rence
                seed=42,  # Assurer la coh√©rence des r√©sultats
                response_format={"type": "json_object"}  # Forcer une r√©ponse JSON
            )
            
            result = json.loads(response.choices[0].message.content)
            st.success("Analyse r√©alis√©e avec gpt-3.5-turbo")
        
        # Stocker le r√©sultat dans le cache
        st.session_state.analysis_cache[content_hash] = result
        return result

    except Exception as e:
        st.error(f"Erreur lors de l'analyse avec OpenAI: {str(e)}")
        # Retourner une analyse par d√©faut en cas d'erreur
        return {
            "document1_analysis": [{"title": "Analyse manuelle n√©cessaire", "content": "Une erreur s'est produite lors de l'analyse automatique."}],
            "document2_analysis": [{"title": "Analyse manuelle n√©cessaire", "content": "Une erreur s'est produite lors de l'analyse automatique."}],
            "themes": ["Non disponible suite √† une erreur"],
            "coherence_analysis": {"coherence_level": "ind√©termin√©e", "details": "L'analyse n'a pas pu √™tre effectu√©e automatiquement."},
            "observations": ["Veuillez r√©essayer ou effectuer une analyse manuelle."]
        }
        
def plot_themes_chart(themes):
    """Cr√©e un graphique des th√®mes principaux"""
    if not themes:
        return None

    # Pr√©parer les donn√©es (tous les th√®mes ont le m√™me poids par d√©faut)
    labels = themes
    sizes = [1] * len(themes)

    # Graphique camembert
    fig, ax = plt.subplots(figsize=(10, 6))
    wedges, texts, autotexts = ax.pie(
        sizes, 
        labels=labels, 
        autopct='%1.1f%%',
        textprops={'fontsize': 9}
    )

    # Ajuster les propri√©t√©s du texte
    plt.setp(autotexts, size=8, weight='bold')
    plt.setp(texts, size=8)

    plt.title('Th√®mes principaux identifi√©s')
    plt.tight_layout()
    
    return fig

def generate_pdf_report(analysis, document_type, text1=None, text2=None):
    """
    G√©n√®re un rapport PDF complet de l'analyse des documents.
    """
    from reportlab.lib.pagesizes import A4
    from reportlab.lib import colors
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak
    from reportlab.lib.units import cm
    from io import BytesIO
    import datetime
    
    # Cr√©er un buffer pour stocker le PDF
    buffer = BytesIO()
    
    # Cr√©er le document PDF
    doc = SimpleDocTemplate(buffer, pagesize=A4, 
                           rightMargin=2*cm, leftMargin=2*cm,
                           topMargin=2*cm, bottomMargin=2*cm)
    
    # Contenu du document
    story = []
    
    # Styles
    styles = getSampleStyleSheet()
    styles.add(ParagraphStyle(name='Center', parent=styles['Heading1'], alignment=1))
    styles.add(ParagraphStyle(name='Justify', parent=styles['Normal'], alignment=4))
    styles.add(ParagraphStyle(name='Small', parent=styles['Normal'], fontSize=8))
    
    # Titre et date
    today = datetime.datetime.now().strftime("%d/%m/%Y")
    title = f"Analyse de Documents - Type {document_type.capitalize()}"
    story.append(Paragraph(title, styles['Center']))
    story.append(Paragraph(f"Rapport g√©n√©r√© le {today}", styles['Normal']))
    story.append(Spacer(1, 0.5*cm))
    
    # Informations g√©n√©rales
    story.append(Paragraph("Informations g√©n√©rales", styles['Heading2']))
    
    info_data = [
        ["Type de document", document_type.capitalize()],
        ["Niveau de coh√©rence", analysis['coherence_analysis']['coherence_level']]
    ]
    
    # Cr√©er un tableau pour les informations
    info_table = Table(info_data, colWidths=[5*cm, 10*cm])
    info_table.setStyle(TableStyle([
        ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),
        ('BACKGROUND', (0, 0), (0, -1), colors.lightgrey),
        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
        ('PADDING', (0, 0), (-1, -1), 6),
    ]))
    story.append(info_table)
    story.append(Spacer(1, 0.5*cm))
    
    # Analyse de coh√©rence
    if 'details' in analysis['coherence_analysis']:
        story.append(Paragraph("Analyse de coh√©rence", styles['Heading3']))
        story.append(Paragraph(analysis['coherence_analysis']['details'], styles['Justify']))
        story.append(Spacer(1, 0.5*cm))
    
    # Th√®mes principaux
    if analysis["themes"]:
        story.append(Paragraph("Th√®mes principaux", styles['Heading2']))
        for theme in analysis["themes"]:
            story.append(Paragraph(f"‚Ä¢ {theme}", styles['Normal']))
        story.append(Spacer(1, 0.5*cm))
    
    # Analyse du document 1
    story.append(Paragraph("Analyse du Document 1", styles['Heading2']))
    for section in analysis["document1_analysis"]:
        story.append(Paragraph(section["title"], styles['Heading3']))
        story.append(Paragraph(section["content"], styles['Justify']))
        story.append(Spacer(1, 0.3*cm))
    
    # Analyse du document 2
    story.append(PageBreak())
    story.append(Paragraph("Analyse du Document 2", styles['Heading2']))
    for section in analysis["document2_analysis"]:
        story.append(Paragraph(section["title"], styles['Heading3']))
        story.append(Paragraph(section["content"], styles['Justify']))
        story.append(Spacer(1, 0.3*cm))
    
    # Observations
    story.append(Paragraph("Observations", styles['Heading2']))
    for i, obs in enumerate(analysis["observations"]):
        story.append(Paragraph(f"{i+1}. {obs}", styles['Normal']))
    
    story.append(Spacer(1, 0.5*cm))
    
    # Pied de page
    story.append(Spacer(1, 1*cm))
    story.append(Paragraph("Ce rapport a √©t√© g√©n√©r√© automatiquement et sert uniquement √† titre indicatif. "
                          "Pour une analyse compl√®te, veuillez consulter un professionnel du domaine concern√©.", 
                          styles['Small']))
    
    # Construire le PDF
    doc.build(story)
    
    # R√©cup√©rer le contenu du buffer
    pdf_content = buffer.getvalue()
    buffer.close()
    
    return pdf_content

# Interface utilisateur Streamlit
def main():
    st.title("Analyseur de Documents avec GPT-4o-mini")
    st.markdown("""
    Cet outil analyse la coh√©rence entre deux documents en utilisant GPT-4o-mini.
    Pour les m√™mes documents en entr√©e, l'analyse sera identique √† chaque ex√©cution.
    """)

    # Sidebar pour la configuration
    st.sidebar.header("Configuration")

    document_type = st.sidebar.selectbox(
        "Type de document",
        options=["rapport", "contrat", "article", "correspondance", "autre"],
        index=0
    )

    # Interface principale avec onglets
    tab1, tab2 = st.tabs(["Saisie manuelle", "T√©l√©chargement de fichiers"])

    # Onglet 1: Saisie manuelle
    with tab1:
        with st.form("input_form_manual"):
            col1, col2 = st.columns(2)

            with col1:
                st.subheader("Document 1")
                document1_manual = st.text_area(
                    "Copiez-collez le contenu du premier document",
                    height=250
                )

            with col2:
                st.subheader("Document 2")
                document2_manual = st.text_area(
                    "Copiez-collez le contenu du deuxi√®me document",
                    height=250
                )

            specific_questions = st.text_area(
                "Questions sp√©cifiques (facultatif)",
                help="Avez-vous des questions particuli√®res concernant ces documents?"
            )

            submitted_manual = st.form_submit_button("Analyser les documents")

    # Onglet 2: T√©l√©chargement de fichiers
    with tab2:
        with st.form("input_form_files"):
            col1, col2 = st.columns(2)

            with col1:
                st.subheader("Document 1")
                doc1_files = st.file_uploader(
                    "T√©l√©chargez le(s) fichier(s) du document 1 (PDF, Word, TXT, Image)",
                    type=["pdf", "docx", "txt", "png", "jpg", "jpeg"],
                    accept_multiple_files=True
                )

                if doc1_files:
                    st.write(f"{len(doc1_files)} fichier(s) t√©l√©charg√©(s) pour le document 1")

            with col2:
                st.subheader("Document 2")
                doc2_files = st.file_uploader(
                    "T√©l√©chargez le(s) fichier(s) du document 2 (PDF, Word, TXT, Image)",
                    type=["pdf", "docx", "txt", "png", "jpg", "jpeg"],
                    accept_multiple_files=True
                )

                if doc2_files:
                    st.write(f"{len(doc2_files)} fichier(s) t√©l√©charg√©(s) pour le document 2")

            specific_questions_file = st.text_area(
                "Questions sp√©cifiques (facultatif)",
                help="Avez-vous des questions particuli√®res concernant ces documents?"
            )

            submitted_files = st.form_submit_button("Analyser les fichiers")

    # Traitement du formulaire de saisie manuelle
    if submitted_manual:
        if not document1_manual or not document2_manual:
            st.error("Veuillez remplir les champs obligatoires (document 1 et document 2).")
        else:
            with st.spinner("Analyse en cours..."):
                # Analyser les documents avec OpenAI
                analysis = analyze_with_openai(document1_manual, document2_manual, document_type)
                if analysis:
                    st.session_state.analysis = analysis
                    st.session_state.analysis_complete = True
                    # Sauvegarder les textes originaux pour l'export PDF
                    st.session_state.document1_text = document1_manual
                    st.session_state.document2_text = document2_manual

    # Traitement du formulaire de t√©l√©chargement de fichiers
    if submitted_files:
        if not doc1_files or not doc2_files:
            st.error("Veuillez t√©l√©charger au moins un fichier pour chaque document.")
        else:
            with st.spinner("Extraction et analyse des fichiers en cours..."):
                # Extraire et combiner le texte de tous les fichiers
                document1_combined = process_multiple_files(doc1_files)
                document2_combined = process_multiple_files(doc2_files)

                if not document1_combined or not document2_combined:
                    st.error("Impossible d'extraire le texte des fichiers t√©l√©charg√©s.")
                else:
                    # Afficher un r√©sum√© du texte extrait
                    st.info(f"Texte extrait: Document 1 ({len(document1_combined)} caract√®res), Document 2 ({len(document2_combined)} caract√®res)")

                    # Analyser les documents avec OpenAI
                    analysis = analyze_with_openai(document1_combined, document2_combined, document_type)
                    if analysis:
                        st.session_state.analysis = analysis
                        st.session_state.analysis_complete = True
                        # Sauvegarder les textes originaux pour l'export PDF
                        st.session_state.document1_text = document1_combined
                        st.session_state.document2_text = document2_combined

    # Afficher les r√©sultats
    if st.session_state.analysis_complete:
        analysis = st.session_state.analysis

        st.header("R√©sultats de l'analyse")

        # Afficher le niveau de coh√©rence
        coherence_level = analysis['coherence_analysis']['coherence_level']
        coherence_details = analysis['coherence_analysis']['details']
        
        # D√©finir la couleur en fonction du niveau de coh√©rence
        color_map = {"√©lev√©e": "success", "moyenne": "warning", "faible": "error"}
        alert_type = color_map.get(coherence_level, "info")
        
        if alert_type == "success":
            st.success(f"Niveau de coh√©rence: {coherence_level}. {coherence_details}")
        elif alert_type == "warning":
            st.warning(f"Niveau de coh√©rence: {coherence_level}. {coherence_details}")
        elif alert_type == "error":
            st.error(f"Niveau de coh√©rence: {coherence_level}. {coherence_details}")
        else:
            st.info(f"Niveau de coh√©rence: {coherence_level}. {coherence_details}")

        # Afficher les th√®mes principaux
        st.subheader("Th√®mes principaux")
        for theme in analysis["themes"]:
            st.markdown(f"- {theme}")

        # Visualisation graphique des th√®mes
        if len(analysis["themes"]) > 1:
            st.subheader("Visualisation des th√®mes")
            fig = plot_themes_chart(analysis["themes"])
            if fig:
                st.pyplot(fig)

        # Afficher l'analyse des documents dans des onglets
        doc1_tab, doc2_tab = st.tabs(["Analyse Document 1", "Analyse Document 2"])
        
        with doc1_tab:
            for section in analysis["document1_analysis"]:
                with st.expander(section["title"]):
                    st.markdown(section["content"])
        
        with doc2_tab:
            for section in analysis["document2_analysis"]:
                with st.expander(section["title"]):
                    st.markdown(section["content"])

        # Observations
        st.subheader("Observations")
        for i, obs in enumerate(analysis["observations"]):
            st.markdown(f"{i+1}. {obs}")

        # Options d'export
        st.header("Exporter les r√©sultats")
        col1, col2 = st.columns(2)
        
        with col1:
            # Export JSON
            st.download_button(
                label="T√©l√©charger l'analyse en JSON",
                data=json.dumps(analysis, indent=2, ensure_ascii=False).encode('utf-8'),
                file_name='analyse_documents.json',
                mime='application/json',
            )
        
        with col2:
            # Export PDF
            try:
                document1_text = st.session_state.get('document1_text', '')
                document2_text = st.session_state.get('document2_text', '')
                
                # G√©n√©rer le rapport PDF
                pdf_content = generate_pdf_report(
                    analysis, 
                    document_type, 
                    document1_text, 
                    document2_text
                )
                
                # Bouton de t√©l√©chargement pour le PDF
                st.download_button(
                    label="T√©l√©charger le rapport PDF",
                    data=pdf_content,
                    file_name="rapport_analyse_documents.pdf",
                    mime="application/pdf",
                )
            except Exception as e:
                st.error(f"Erreur lors de la g√©n√©ration du PDF: {str(e)}")
                st.info("Assurez-vous d'avoir install√© reportlab avec 'pip install reportlab'")

if __name__ == "__main__":
    main()
